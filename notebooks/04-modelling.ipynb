{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Modeling\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart22 = pd.read_csv('~/Desktop/capstone-project-Tasnimacj/data/cleaned_data/heart22_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246013 entries, 0 to 246012\n",
      "Data columns (total 43 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   Unnamed: 0                     246013 non-null  int64  \n",
      " 1   Female                         246013 non-null  int64  \n",
      " 2   GeneralHealth                  246013 non-null  int64  \n",
      " 3   PhysicalHealthDays             246013 non-null  float64\n",
      " 4   MentalHealthDays               246013 non-null  float64\n",
      " 5   LastCheckupTime                246013 non-null  int64  \n",
      " 6   PhysicalActivities             246013 non-null  int64  \n",
      " 7   SleepHours                     246013 non-null  float64\n",
      " 8   RemovedTeeth                   246013 non-null  int64  \n",
      " 9   HadHeartAttack                 246013 non-null  int64  \n",
      " 10  HadAngina                      246013 non-null  int64  \n",
      " 11  HadStroke                      246013 non-null  int64  \n",
      " 12  HadAsthma                      246013 non-null  int64  \n",
      " 13  HadSkinCancer                  246013 non-null  int64  \n",
      " 14  HadCOPD                        246013 non-null  int64  \n",
      " 15  HadDepressiveDisorder          246013 non-null  int64  \n",
      " 16  HadKidneyDisease               246013 non-null  int64  \n",
      " 17  HadArthritis                   246013 non-null  int64  \n",
      " 18  HadDiabetes                    246013 non-null  int64  \n",
      " 19  DeafOrHardOfHearing            246013 non-null  int64  \n",
      " 20  BlindOrVisionDifficulty        246013 non-null  int64  \n",
      " 21  DifficultyConcentrating        246013 non-null  int64  \n",
      " 22  DifficultyWalking              246013 non-null  int64  \n",
      " 23  DifficultyDressingBathing      246013 non-null  int64  \n",
      " 24  DifficultyErrands              246013 non-null  int64  \n",
      " 25  SmokerStatus                   246013 non-null  int64  \n",
      " 26  ECigaretteUsage                246013 non-null  int64  \n",
      " 27  ChestScan                      246013 non-null  int64  \n",
      " 28  AgeCategory                    246013 non-null  int64  \n",
      " 29  HeightInMeters                 246013 non-null  float64\n",
      " 30  WeightInKilograms              246013 non-null  float64\n",
      " 31  BMI                            246013 non-null  float64\n",
      " 32  AlcoholDrinkers                246013 non-null  int64  \n",
      " 33  HIVTesting                     246013 non-null  int64  \n",
      " 34  FluVaxLast12                   246013 non-null  int64  \n",
      " 35  PneumoVaxEver                  246013 non-null  int64  \n",
      " 36  TetanusLast10Tdap              246013 non-null  int64  \n",
      " 37  HighRiskLastYear               246013 non-null  int64  \n",
      " 38  CovidPos                       246013 non-null  int64  \n",
      " 39  RaceEthnicity_Black only       246013 non-null  int64  \n",
      " 40  RaceEthnicity_Hispanic         246013 non-null  int64  \n",
      " 41  RaceEthnicity_Multiracial      246013 non-null  int64  \n",
      " 42  RaceEthnicity_Other race only  246013 non-null  int64  \n",
      "dtypes: float64(6), int64(37)\n",
      "memory usage: 80.7 MB\n"
     ]
    }
   ],
   "source": [
    "heart22.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart22['HadAngina'] # Target Variable\n",
    "X = heart22.drop('HadAngina', axis=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (246013,)\n",
      "Shape of X: (246013, 42)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of y:', y.shape)\n",
    "print('Shape of X:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remainder set has 196810 data points.\n",
      "The test set has 49203 data points.\n"
     ]
    }
   ],
   "source": [
    "#1st split\n",
    "\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=0.2, random_state=25, stratify=y)\n",
    "\n",
    "print(f'The remainder set has {len(X_rem)} data points.')\n",
    "print(f'The test set has {len(X_test)} data points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(X_rem)\n",
    "X_rem_ss = ss.transform(X_rem)\n",
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_log_reg = LogisticRegression(random_state=25)\n",
    "baseline_log_reg.fit(X_rem_ss, y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on remainder set: 0.9450586860423759\n",
      "Accuracy on test set: 0.9446375221023109\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on remainder set: {baseline_log_reg.score(X_rem_ss, y_rem)}')\n",
    "print(f'Accuracy on test set: {baseline_log_reg.score(X_test_ss, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HadAngina\n",
       "0    46212\n",
       "1     2991\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class distribution\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>45642</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2154</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        45642          570\n",
       "true 1         2154          837"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 27.98%\n",
      "Precision score: 59.49%\n",
      "F1 score: 38.06%\n"
     ]
    }
   ],
   "source": [
    "# predict classification\n",
    "y_test_pred = baseline_log_reg.predict(X_test_ss)\n",
    "\n",
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"my_pca\", PCA(n_components=20)),\n",
    "                 (\"model\", LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_values = [.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Parameters\n",
    "log_reg_param = [\n",
    "\n",
    "    {'scaler': [ StandardScaler()],\n",
    "     'my_pca__n_components': [20],\n",
    "     'model': [LogisticRegression(solver='saga',random_state=1, n_jobs=-1, max_iter=10000)], \n",
    "     'model__C': c_values,\n",
    "     'model__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe,param_grid=log_reg_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_lr = grid.fit(X_rem,y_rem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=0.001, max_iter=10000, n_jobs=-1, random_state=1,\n",
       "                    solver='saga'),\n",
       " 'model__C': 0.001,\n",
       " 'model__penalty': 'l2',\n",
       " 'my_pca__n_components': 20,\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='/var/folders/r3/bz5mjtds4dvdw0hskxwvs9vc0000gp/T/tmphe1wkm0v',\n",
       "         steps=[('scaler', StandardScaler()), ('my_pca', PCA(n_components=20)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.001, max_iter=10000, n_jobs=-1,\n",
       "                                    random_state=1, solver='saga'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.9424876784716224\n",
      "Best accuracy on the test set: 0.9429709570554641\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracies\n",
    "print(f\"Best accuracy on the remainder set: {fittedgrid_lr.score(X_rem, y_rem)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_lr.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>45845</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2439</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        45845          367\n",
       "true 1         2439          552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 18.46%\n",
      "Precision score: 60.07%\n",
      "F1 score: 28.24%\n"
     ]
    }
   ],
   "source": [
    "# predict classification\n",
    "y_test_pred = fittedgrid_lr.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"my_pca\", PCA(n_components=20)),\n",
    "                 (\"dt_model\", DecisionTreeClassifier())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_param  = {\"scaler\":[StandardScaler(), None],\n",
    "            \"my_pca__n_components\":[20],\n",
    "            \"dt_model__max_depth\": [None, 2, 4, 6, 8,10],\n",
    "            \"dt_model__min_samples_leaf\": [2, 5, 10] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe,param_grid=dt_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_dt = grid.fit(X_rem,y_rem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'my_pca', 'dt_model', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'my_pca__copy', 'my_pca__iterated_power', 'my_pca__n_components', 'my_pca__random_state', 'my_pca__svd_solver', 'my_pca__tol', 'my_pca__whiten', 'dt_model__ccp_alpha', 'dt_model__class_weight', 'dt_model__criterion', 'dt_model__max_depth', 'dt_model__max_features', 'dt_model__max_leaf_nodes', 'dt_model__min_impurity_decrease', 'dt_model__min_impurity_split', 'dt_model__min_samples_leaf', 'dt_model__min_samples_split', 'dt_model__min_weight_fraction_leaf', 'dt_model__random_state', 'dt_model__splitter'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt_model__max_depth': 6,\n",
       " 'dt_model__min_samples_leaf': 10,\n",
       " 'my_pca__n_components': 20,\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='/var/folders/r3/bz5mjtds4dvdw0hskxwvs9vc0000gp/T/tmphe1wkm0v',\n",
       "         steps=[('scaler', StandardScaler()), ('my_pca', PCA(n_components=20)),\n",
       "                ('dt_model',\n",
       "                 DecisionTreeClassifier(max_depth=6, min_samples_leaf=10))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.9402977490981149\n",
      "Best accuracy on the test set: 0.9395768550698128\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracies\n",
    "print(f\"Best accuracy on the remainder set: {fittedgrid_dt.score(X_rem, y_rem)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_dt.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>45967</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2728</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        45967          245\n",
       "true 1         2728          263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 8.79%\n",
      "Precision score: 51.77%\n",
      "F1 score: 15.03%\n"
     ]
    }
   ],
   "source": [
    "# predict classification\n",
    "y_test_pred = fittedgrid_dt.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#non scaled\n",
    "# train \n",
    "# scale after smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rem_sm, y_rem_sm = SMOTE(random_state=1).fit_resample(X_rem, y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HadAngina\n",
       "0    184848\n",
       "1     11962\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled class distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HadAngina\n",
       "0    184848\n",
       "1    184848\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print('Original class distribution')\n",
    "display(pd.Series(y_rem).value_counts().sort_index())\n",
    "\n",
    "print('\\nResampled class distribution')\n",
    "display(pd.Series(y_rem_sm).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"my_pca\", PCA(n_components=20)),\n",
    "                 (\"model\", LogisticRegression())], memory=cachedir)\n",
    "log_reg_param = [\n",
    "\n",
    "    {'scaler': [ StandardScaler()],\n",
    "     'my_pca__n_components': [20],\n",
    "     'model': [LogisticRegression(solver='saga',random_state=1, n_jobs=-1, max_iter=10000)], \n",
    "     'model__C': c_values,\n",
    "     'model__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_sm = GridSearchCV(estimator=pipe,param_grid=log_reg_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_lr_sm = grid_sm.fit(X_rem_sm,y_rem_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.8598605340604172\n",
      "Best accuracy on the test set: 0.8297868016177875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>39380</td>\n",
       "      <td>6832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>1543</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        39380         6832\n",
       "true 1         1543         1448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 48.41%\n",
      "Precision score: 17.49%\n",
      "F1 score: 25.69%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Best accuracy on the remainder set: {fittedgrid_lr_sm.score(X_rem_sm, y_rem_sm)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_lr_sm.score(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "# predict classification\n",
    "y_test_pred = fittedgrid_lr_sm.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"my_pca\", PCA(n_components=20)),\n",
    "                 (\"dt_model\", DecisionTreeClassifier())], memory=cachedir)\n",
    "\n",
    "dt_param  = {\"scaler\":[StandardScaler(), None],\n",
    "            \"my_pca__n_components\":[20],\n",
    "            \"dt_model__max_depth\": [None, 2, 4, 6, 8,10],\n",
    "            \"dt_model__min_samples_leaf\": [2, 5, 10] }\n",
    "\n",
    "\n",
    "grid_sm = GridSearchCV(estimator=pipe,param_grid=dt_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_dt_sm = grid_sm.fit(X_rem_sm,y_rem_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.863314723448455\n",
      "Best accuracy on the test set: 0.8128975875454749\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>38756</td>\n",
       "      <td>7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>1750</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        38756         7456\n",
       "true 1         1750         1241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 41.49%\n",
      "Precision score: 14.27%\n",
      "F1 score: 21.24%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best accuracy on the remainder set: {fittedgrid_dt_sm.score(X_rem_sm, y_rem_sm)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_dt_sm.score(X_test, y_test)}\")\n",
    "\n",
    "# predict classification\n",
    "y_test_pred = fittedgrid_dt_sm.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table that compares baseline,Logreg test, DT test, SMOTE logreg test, SMOTE DT test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'F1 score' :[38.06,28.24,15.03,25.69,21.24],\n",
    "     'Recall score':[27.98,18.46,8.79,48.41,41.49], \n",
    "     'Precision score':[59.49,60.07,51.77,17.49,14.27],\n",
    "      'Accuracy':[94.46,94.30,93.96,82.98,81.29]}\n",
    "\n",
    "\n",
    "scores = pd.DataFrame(\n",
    "    data = data,\n",
    "    index = ['Basline LogReg', 'Best LogReg', 'Best DT','Best SMOTE LogReg', 'Best SMOTE DT' ],\n",
    "    columns = ['F1 score','Recall score', 'Precision score', 'Accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall score</th>\n",
       "      <th>Precision score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Basline LogReg</th>\n",
       "      <td>38.06</td>\n",
       "      <td>27.98</td>\n",
       "      <td>59.49</td>\n",
       "      <td>94.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best LogReg</th>\n",
       "      <td>28.24</td>\n",
       "      <td>18.46</td>\n",
       "      <td>60.07</td>\n",
       "      <td>94.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best DT</th>\n",
       "      <td>15.03</td>\n",
       "      <td>8.79</td>\n",
       "      <td>51.77</td>\n",
       "      <td>93.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best SMOTE LogReg</th>\n",
       "      <td>25.69</td>\n",
       "      <td>48.41</td>\n",
       "      <td>17.49</td>\n",
       "      <td>82.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best SMOTE DT</th>\n",
       "      <td>21.24</td>\n",
       "      <td>41.49</td>\n",
       "      <td>14.27</td>\n",
       "      <td>81.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F1 score  Recall score  Precision score  Accuracy\n",
       "Basline LogReg        38.06         27.98            59.49     94.46\n",
       "Best LogReg           28.24         18.46            60.07     94.30\n",
       "Best DT               15.03          8.79            51.77     93.96\n",
       "Best SMOTE LogReg     25.69         48.41            17.49     82.98\n",
       "Best SMOTE DT         21.24         41.49            14.27     81.29"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
