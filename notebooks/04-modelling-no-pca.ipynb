{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Modeling without PCA\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "Introduction\n",
    "\n",
    "\n",
    "In this notebook, I will be building two types classification models. Using Logistic Regression and Decision Trees, we will see if we can correctly classify our target variable and predict the classes of new datapoints. For now I will train my models without PCA.\n",
    "I will train each model with a portion of the dataset and then compare the outputs with my test set. \n",
    "\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart22 = pd.read_csv('~/Desktop/capstone-project-Tasnimacj/data/cleaned_data/heart22_preprocessed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 246013 entries, 0 to 246012\n",
      "Data columns (total 42 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   Female                         246013 non-null  int64  \n",
      " 1   GeneralHealth                  246013 non-null  int64  \n",
      " 2   PhysicalHealthDays             246013 non-null  float64\n",
      " 3   MentalHealthDays               246013 non-null  float64\n",
      " 4   LastCheckupTime                246013 non-null  int64  \n",
      " 5   PhysicalActivities             246013 non-null  int64  \n",
      " 6   SleepHours                     246013 non-null  float64\n",
      " 7   RemovedTeeth                   246013 non-null  int64  \n",
      " 8   HadHeartAttack                 246013 non-null  int64  \n",
      " 9   HadAngina                      246013 non-null  int64  \n",
      " 10  HadStroke                      246013 non-null  int64  \n",
      " 11  HadAsthma                      246013 non-null  int64  \n",
      " 12  HadSkinCancer                  246013 non-null  int64  \n",
      " 13  HadCOPD                        246013 non-null  int64  \n",
      " 14  HadDepressiveDisorder          246013 non-null  int64  \n",
      " 15  HadKidneyDisease               246013 non-null  int64  \n",
      " 16  HadArthritis                   246013 non-null  int64  \n",
      " 17  HadDiabetes                    246013 non-null  int64  \n",
      " 18  DeafOrHardOfHearing            246013 non-null  int64  \n",
      " 19  BlindOrVisionDifficulty        246013 non-null  int64  \n",
      " 20  DifficultyConcentrating        246013 non-null  int64  \n",
      " 21  DifficultyWalking              246013 non-null  int64  \n",
      " 22  DifficultyDressingBathing      246013 non-null  int64  \n",
      " 23  DifficultyErrands              246013 non-null  int64  \n",
      " 24  SmokerStatus                   246013 non-null  int64  \n",
      " 25  ECigaretteUsage                246013 non-null  int64  \n",
      " 26  ChestScan                      246013 non-null  int64  \n",
      " 27  AgeCategory                    246013 non-null  int64  \n",
      " 28  HeightInMeters                 246013 non-null  float64\n",
      " 29  WeightInKilograms              246013 non-null  float64\n",
      " 30  BMI                            246013 non-null  float64\n",
      " 31  AlcoholDrinkers                246013 non-null  int64  \n",
      " 32  HIVTesting                     246013 non-null  int64  \n",
      " 33  FluVaxLast12                   246013 non-null  int64  \n",
      " 34  PneumoVaxEver                  246013 non-null  int64  \n",
      " 35  TetanusLast10Tdap              246013 non-null  int64  \n",
      " 36  HighRiskLastYear               246013 non-null  int64  \n",
      " 37  CovidPos                       246013 non-null  int64  \n",
      " 38  RaceEthnicity_Black only       246013 non-null  int64  \n",
      " 39  RaceEthnicity_Hispanic         246013 non-null  int64  \n",
      " 40  RaceEthnicity_Multiracial      246013 non-null  int64  \n",
      " 41  RaceEthnicity_Other race only  246013 non-null  int64  \n",
      "dtypes: float64(6), int64(36)\n",
      "memory usage: 80.7 MB\n"
     ]
    }
   ],
   "source": [
    "heart22.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I load in the data that we saved from the previous notebook. Checking if our dataset is properly encoded, with 0 null values and has a correct index. Everything looks good, so we can move straight into modeling now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart22['HadAngina'] # Target Variable\n",
    "X = heart22.drop('HadAngina', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (246013,)\n",
      "Shape of X: (246013, 41)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of y:', y.shape)\n",
    "print('Shape of X:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data into our feature columns and our target variable. We will be putting our X into our models and comparing the outputs with our y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remainder set has 196810 data points.\n",
      "The test set has 49203 data points.\n"
     ]
    }
   ],
   "source": [
    "#1st split\n",
    "\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=0.2, random_state=25, stratify=y)\n",
    "\n",
    "print(f'The remainder set has {len(X_rem)} data points.')\n",
    "print(f'The test set has {len(X_test)} data points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, we need to split our data into a training set and a test set. Here I did a 80:20 split, keeping an even distribution of y variables in each split. \n",
    "We use the train set to fit the model and then evaluate on the test set. Splitting the datapoints helps prevent overfitting and a way to accurately check model performance. By having unseen data, we can come close to replicating real life scenarios that the model will face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### 1 Baseline Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first model, I will attempt to create a model that has no hyperparameter optimization. This will be a a model we can use for comparison. I am expecting that this model will perform poorly and will be very good at predicting 0, or 'did not have angina'\n",
    "As logistic regression takes L2 Regularisation as its default penalty, I will need to scale my data beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(X_rem)\n",
    "X_rem_ss = ss.transform(X_rem)\n",
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_log_reg = LogisticRegression(random_state=1)\n",
    "baseline_log_reg.fit(X_rem_ss, y_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the model and then fit the model on our y remainder data and the scaled X remainder data. We then input unknown data and compare accuracy scores with our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on remainder set: 0.9450840912555256\n",
      "Accuracy on test set: 0.9445359022823812\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on remainder set: {baseline_log_reg.score(X_rem_ss, y_rem)}')\n",
    "print(f'Accuracy on test set: {baseline_log_reg.score(X_test_ss, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy on the remainder and test set is the same, 94.5%. This means our model has correctly classified 94.5% of the data points in both sets. This shows that the model has a good fit, and can handle unseen data.\n",
    "\n",
    "However, accuracy is not a good indicator of the model outcomes as it does not show if our model is behaving how we expect. \n",
    "We can look further by using a classification report and confusion matrix to see what datapoints were classified as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>45639</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2156</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        45639          573\n",
       "true 1         2156          835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 27.92%\n",
      "Precision score: 59.30%\n",
      "F1 score: 37.96%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_pred = baseline_log_reg.predict(X_test_ss)\n",
    "\n",
    "\n",
    "cmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(cmat)\n",
    "\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     46212\n",
      "           1       0.59      0.28      0.38      2991\n",
      "\n",
      "    accuracy                           0.94     49203\n",
      "   macro avg       0.77      0.63      0.68     49203\n",
      "weighted avg       0.93      0.94      0.94     49203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results \n",
    "baseline_logreg_recall = round(recall_score(y_test, y_test_pred)*100, 2)\n",
    "baseline_logreg_precision = round(precision_score(y_test, y_test_pred)*100, 2)\n",
    "baseline_logreg_f1 = round(f1_score(y_test, y_test_pred)*100, 2)\n",
    "baseline_logreg_accu = round(baseline_log_reg.score(X_test_ss, y_test)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our model was 94.5% accurate, it was only good at predicting 'Had no Angina'. This is most likely due to the imbalance in our dataset. It has seen more cases where y would be '0' than when y would be '1'.\n",
    "\n",
    " My main goal is to get high recall without sacrificing precision and accuracy. For my problem, it would be better to have more false positives than false negatives. It would be worse to mischaracterise someone as not at risk than saying they could be at risk. My model could only classify 837 datapoints correcty as '1' out of 2991 '1' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### 2 Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline\n",
    "\n",
    "Using a pipeline, I want to find the best hyperparameters for my model. I set up a pipeline that contains a scaler and the model of our choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"model\", LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Optimisation\n",
    "\n",
    "Setting up a parameter grid with what I would like to change in my model. I want to explore different c values and the model penalty. For now, I only want to scale my data using a standard scaler and look at the top 20 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_values = [.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Parameters\n",
    "log_reg_param = [\n",
    "\n",
    "    {'scaler': [ StandardScaler()],\n",
    "     'model': [LogisticRegression(solver='saga',random_state=1, n_jobs=-1, max_iter=10000)], \n",
    "     'model__C': c_values,\n",
    "     'model__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe,param_grid=log_reg_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_lr = grid.fit(X_rem,y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=0.01, max_iter=10000, n_jobs=-1, penalty='l1',\n",
       "                    random_state=1, solver='saga'),\n",
       " 'model__C': 0.01,\n",
       " 'model__penalty': 'l1',\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch looks at different parameter settings across 5 cross folds on our Remainder set. It does this to find the best model settings whilst preventing data leakage and overfitting on our train set. \n",
    "GridSearch has found that the best parameters for our Logistic Regression is having a C value of 0.001, which means we need a strong regularization strength. We need a l2 penalty to help shrink coefficients to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25500318,  0.36090165,  0.00575559,  0.01113913, -0.15727343,\n",
       "         0.02174119, -0.01699133,  0.01770615,  0.55207111,  0.06057528,\n",
       "         0.02307375,  0.03691191,  0.08868733,  0.03262813,  0.09887653,\n",
       "         0.10604211,  0.09466208,  0.01846323,  0.00157875,  0.01583623,\n",
       "         0.01506998, -0.00387145,  0.        , -0.01317377,  0.        ,\n",
       "         0.3121227 ,  0.6834773 ,  0.        ,  0.00087678,  0.03905761,\n",
       "         0.        ,  0.        ,  0.02235304,  0.14939088,  0.02885227,\n",
       "         0.        ,  0.0393657 , -0.04762283, -0.03940759,  0.00582674,\n",
       "        -0.02161171]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_lr.best_estimator_.named_steps[\"model\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 41), indices imply (41, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Tasnima/Desktop/capstone-project-Tasnimacj/notebooks/04-modelling-no-pca.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Tasnima/Desktop/capstone-project-Tasnimacj/notebooks/04-modelling-no-pca.ipynb#Y155sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m coeff \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(fittedgrid_lr\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mnamed_steps[\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mcoef_, index\u001b[39m=\u001b[39;49mX\u001b[39m.\u001b[39;49mcolumns, columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mCoefficients\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Tasnima/Desktop/capstone-project-Tasnimacj/notebooks/04-modelling-no-pca.ipynb#Y155sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m coeff\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCoefficients\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Tasnima/Desktop/capstone-project-Tasnimacj/notebooks/04-modelling-no-pca.ipynb#Y155sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m coeff\u001b[39m.\u001b[39mplot(kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m'\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m6\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/capstone/lib/python3.8/site-packages/pandas/core/frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    747\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    748\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    749\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m             copy\u001b[39m=\u001b[39m_copy,\n\u001b[1;32m    756\u001b[0m         )\n\u001b[1;32m    757\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    759\u001b[0m             data,\n\u001b[1;32m    760\u001b[0m             index,\n\u001b[1;32m    761\u001b[0m             columns,\n\u001b[1;32m    762\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    763\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    764\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    765\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/anaconda3/envs/capstone/lib/python3.8/site-packages/pandas/core/internals/construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    333\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    334\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/capstone/lib/python3.8/site-packages/pandas/core/internals/construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    407\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 408\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1, 41), indices imply (41, 1)"
     ]
    }
   ],
   "source": [
    "coeff = pd.DataFrame(fittedgrid_lr.best_estimator_.named_steps[\"model\"].coef_, index=X.columns, columns=[\"Coefficients\"])\n",
    "coeff.sort_values(by='Coefficients', ascending=False, inplace=True)\n",
    "coeff.plot(kind='bar', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.9450891722981556\n",
      "Best accuracy on the test set: 0.9448001138141984\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best accuracy on the remainder set: {fittedgrid_lr.score(X_rem, y_rem)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_lr.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>45656</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2160</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        45656          556\n",
       "true 1         2160          831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 27.78%\n",
      "Precision score: 59.91%\n",
      "F1 score: 37.96%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = fittedgrid_lr.predict(X_test)\n",
    "\n",
    "\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results \n",
    "best_lr_recall = round(recall_score(y_test, y_test_pred)*100, 2)\n",
    "best_lr_precision = round(precision_score(y_test, y_test_pred)*100, 2)\n",
    "best_lr_f1 = round(f1_score(y_test, y_test_pred)*100, 2)\n",
    "best_lr_accu = round(fittedgrid_lr.score(X_test_ss, y_test)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decided best logistic regression model is performing worse than our baseline in terms of recall.\n",
    " Perhaps PCA downgraded model performance, we can investigate this further in future notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### 3 Tuning Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline\n",
    "\n",
    "Setting up the pipeline for another classification model, this time I will use Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"dt_model\", DecisionTreeClassifier())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Optimisation\n",
    "\n",
    "For the parameter grid, this time I want to see if scaling data would make a change in modeling. I still 20 components for PCA but explore different options for the trees max_depth and min_samples_leaf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_param  = {\"scaler\":[StandardScaler(), None],\n",
    "            \"dt_model__max_depth\": [None, 2, 4, 6, 8,10],\n",
    "            \"dt_model__min_samples_leaf\": [2, 5, 10] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe,param_grid=dt_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_dt = grid.fit(X_rem,y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt_model__max_depth': 6,\n",
       " 'dt_model__min_samples_leaf': 10,\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_dt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best optimization for our decision tree would be using a standard scaler, having a max_depth of 6 and 10 min_samples_leaf. Scaling my data beforehand seems to be a crucial step for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.9455820334332605\n",
      "Best accuracy on the test set: 0.9447391419222405\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracies\n",
    "print(f\"Best accuracy on the remainder set: {fittedgrid_dt.score(X_rem, y_rem)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_dt.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracies are, again, similar to each other. We have no issue with over/underfitting. The accuracies being in the 90s shows that it is very confident in predicting classes correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>45593</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2100</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        45593          619\n",
       "true 1         2100          891"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 29.79%\n",
      "Precision score: 59.01%\n",
      "F1 score: 39.59%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_pred = fittedgrid_dt.predict(X_test)\n",
    "\n",
    "\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results \n",
    "best_dt_recall = round(recall_score(y_test, y_test_pred)*100, 2)\n",
    "best_dt_precision = round(precision_score(y_test, y_test_pred)*100, 2)\n",
    "best_dt_f1 = round(f1_score(y_test, y_test_pred)*100, 2)\n",
    "best_dt_accu = round(fittedgrid_dt.score(X_test, y_test)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recall score has plummeted to 8%. This model is very bad classifying '1's, so it is unusable.\n",
    "The precision is around 50%, so only about half of its '1' predictions were correct.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### 4 SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in EDA, the actual proportion of 'HadAngina' in our target column was very small. To try and combat this we can sample our data, either using Upsampling, Downsampling or SMOTE. Here, I will be using SMOTE to create 'fake' data points by interpolating between datapoints. I hope to see model performances increase as they can learn better from having a more balanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rem_sm, y_rem_sm = SMOTE(random_state=1).fit_resample(X_rem, y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HadAngina\n",
       "0    184848\n",
       "1     11962\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled class distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HadAngina\n",
       "0    184848\n",
       "1    184848\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Original class distribution')\n",
    "display(pd.Series(y_rem).value_counts().sort_index())\n",
    "\n",
    "print('\\nResampled class distribution')\n",
    "display(pd.Series(y_rem_sm).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE has inflated our '1' distribution to now be equal with the number of '0's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 LogReg\n",
    "\n",
    "Repeating the previous steps again but this time fitting with our new balanced remainder set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"model\", LogisticRegression())], memory=cachedir)\n",
    "log_reg_param = [\n",
    "\n",
    "    {'scaler': [ StandardScaler()],\n",
    "     'model': [LogisticRegression(solver='saga',random_state=1, n_jobs=-1, max_iter=10000)], \n",
    "     'model__C': c_values,\n",
    "     'model__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_sm = GridSearchCV(estimator=pipe,param_grid=log_reg_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_lr_sm = grid_sm.fit(X_rem_sm,y_rem_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=0.01, max_iter=10000, n_jobs=-1, penalty='l1',\n",
       "                    random_state=1, solver='saga'),\n",
       " 'model__C': 0.01,\n",
       " 'model__penalty': 'l1',\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_lr_sm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.8445209036613867\n",
      "Best accuracy on the test set: 0.8155600268276325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>38403</td>\n",
       "      <td>7809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>1266</td>\n",
       "      <td>1725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        38403         7809\n",
       "true 1         1266         1725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 57.67%\n",
      "Precision score: 18.09%\n",
      "F1 score: 27.54%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Best accuracy on the remainder set: {fittedgrid_lr_sm.score(X_rem_sm, y_rem_sm)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_lr_sm.score(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "y_test_pred = fittedgrid_lr_sm.predict(X_test)\n",
    "\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results \n",
    "best_lr_sm_recall = round(recall_score(y_test, y_test_pred)*100, 2)\n",
    "best_lr_sm_precision = round(precision_score(y_test, y_test_pred)*100, 2)\n",
    "best_lr_sm_f1 = round(f1_score(y_test, y_test_pred)*100, 2)\n",
    "best_lr_sm_accu = round(fittedgrid_lr_sm.score(X_test, y_test)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy has dropped, I can see an increase in our recall. The model became more familiar with cases that are classed as '1'  and can recognise it. However, our precision has fallen quite a bit, which shows that the model is not  predicting correctly. I can further investigate and make more changes to find a model with a better recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 DT\n",
    "\n",
    "Fitting a decision tree with our balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"dt_model\", DecisionTreeClassifier())], memory=cachedir)\n",
    "\n",
    "dt_param  = {\"scaler\":[StandardScaler(), None],\n",
    "            \"dt_model__max_depth\": [None, 2, 4, 6, 8,10],\n",
    "            \"dt_model__min_samples_leaf\": [2, 5, 10] }\n",
    "\n",
    "\n",
    "grid_sm = GridSearchCV(estimator=pipe,param_grid=dt_param, cv=5,verbose=1,refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "fittedgrid_dt_sm = grid_sm.fit(X_rem_sm,y_rem_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt_model__max_depth': None, 'dt_model__min_samples_leaf': 2, 'scaler': None}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid_dt_sm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Female', 'GeneralHealth', 'PhysicalHealthDays', 'MentalHealthDays',\n",
       "       'LastCheckupTime', 'PhysicalActivities', 'SleepHours', 'RemovedTeeth',\n",
       "       'HadHeartAttack', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD',\n",
       "       'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis',\n",
       "       'HadDiabetes', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n",
       "       'DifficultyConcentrating', 'DifficultyWalking',\n",
       "       'DifficultyDressingBathing', 'DifficultyErrands', 'SmokerStatus',\n",
       "       'ECigaretteUsage', 'ChestScan', 'AgeCategory', 'HeightInMeters',\n",
       "       'WeightInKilograms', 'BMI', 'AlcoholDrinkers', 'HIVTesting',\n",
       "       'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap',\n",
       "       'HighRiskLastYear', 'CovidPos', 'RaceEthnicity_Black only',\n",
       "       'RaceEthnicity_Hispanic', 'RaceEthnicity_Multiracial',\n",
       "       'RaceEthnicity_Other race only'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "feat_importances = pd.DataFrame({'Feature': X_rem_sm.columns, 'Importance': fittedgrid_dt_sm.best_estimator_.named_steps[\"dt_model\"].feature_importances_,})\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "feat_importances.plot(kind='bar', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on the remainder set: 0.9844331558902449\n",
      "Best accuracy on the test set: 0.8894376359165092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>42801</td>\n",
       "      <td>3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>2029</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0        42801         3411\n",
       "true 1         2029          962"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 32.16%\n",
      "Precision score: 22.00%\n",
      "F1 score: 26.13%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best accuracy on the remainder set: {fittedgrid_dt_sm.score(X_rem_sm, y_rem_sm)}\")\n",
    "print(f\"Best accuracy on the test set: {fittedgrid_dt_sm.score(X_test, y_test)}\")\n",
    "\n",
    "# predict classification\n",
    "y_test_pred = fittedgrid_dt_sm.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, y_test_pred),\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)\n",
    "\n",
    "print(f'Recall score: {recall_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'Precision score: {precision_score(y_test, y_test_pred)*100:0.2f}%')\n",
    "print(f'F1 score: {f1_score(y_test, y_test_pred)*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results \n",
    "best_dt_sm_recall = round(recall_score(y_test, y_test_pred)*100, 2)\n",
    "best_dt_sm_precision = round(precision_score(y_test, y_test_pred)*100, 2)\n",
    "best_dt_sm_f1 = round(f1_score(y_test, y_test_pred)*100, 2)\n",
    "best_dt_sm_accu = round(fittedgrid_dt_sm.score(X_test, y_test)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a huge increase in our recall score. So we can see that SMOTE does help with prediction.\n",
    "\n",
    " But our precision score has dropped again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'F1 score' :[baseline_logreg_f1,best_lr_f1,best_dt_f1,best_lr_sm_f1,best_dt_sm_f1],\n",
    "     'Recall score':[baseline_logreg_recall,best_lr_recall,best_dt_recall,best_lr_sm_recall,best_dt_sm_recall], \n",
    "     'Precision score':[baseline_logreg_precision,best_lr_precision,best_dt_precision,best_lr_sm_precision,best_dt_sm_precision],\n",
    "      'Accuracy':[baseline_logreg_accu,best_lr_accu,best_dt_accu,best_lr_sm_accu,best_dt_sm_accu]}\n",
    "\n",
    "\n",
    "scores = pd.DataFrame(\n",
    "    data = data,\n",
    "    index = ['Basline LogReg', 'Best LogReg', 'Best DT','Best SMOTE LogReg', 'Best SMOTE DT' ],\n",
    "    columns = ['F1 score','Recall score', 'Precision score', 'Accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table that compares the F1, Recall, Precision and Test Accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall score</th>\n",
       "      <th>Precision score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Basline LogReg</th>\n",
       "      <td>37.96</td>\n",
       "      <td>27.92</td>\n",
       "      <td>59.30</td>\n",
       "      <td>94.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best LogReg</th>\n",
       "      <td>26.13</td>\n",
       "      <td>32.16</td>\n",
       "      <td>22.00</td>\n",
       "      <td>93.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best DT</th>\n",
       "      <td>39.59</td>\n",
       "      <td>29.79</td>\n",
       "      <td>59.01</td>\n",
       "      <td>94.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best SMOTE LogReg</th>\n",
       "      <td>27.54</td>\n",
       "      <td>57.67</td>\n",
       "      <td>18.09</td>\n",
       "      <td>81.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best SMOTE DT</th>\n",
       "      <td>26.13</td>\n",
       "      <td>32.16</td>\n",
       "      <td>22.00</td>\n",
       "      <td>88.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F1 score  Recall score  Precision score  Accuracy\n",
       "Basline LogReg        37.96         27.92            59.30     94.45\n",
       "Best LogReg           26.13         32.16            22.00     93.88\n",
       "Best DT               39.59         29.79            59.01     94.47\n",
       "Best SMOTE LogReg     27.54         57.67            18.09     81.56\n",
       "Best SMOTE DT         26.13         32.16            22.00     88.94"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before sampling, my best model was my baseline model. After sampling, I found that my recall improves, which is what I ultimately want.  In future notebooks, I will be looking at modelling without PCA, and trying different hyperparameters. \n",
    "I will have to look into different combinations for my model that would give me a good recall score but also not affect the precision as much.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
